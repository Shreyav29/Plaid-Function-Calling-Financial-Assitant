ğŸ“Š Plaid Function-Calling Financial Assistant

A two-stage Gemini LLM pipeline that routes questions, fetches (fake) Plaid data, and returns natural-language financial insights.

ğŸš€ Overview

This project is a prototype of an AI-powered personal finance assistant that uses Gemini function calling to decide when and how to fetch bank transaction data. It demonstrates an agent-like workflow:

Router LLM â†’ Should I call Plaid?

Tool Call â†’ Fetch fake Plaid data

Analyst LLM â†’ Summarize, analyze, and answer

The system currently uses a fake Plaid API (mock data) for low-friction prototyping.
Later, the mock API can be replaced with real Plaid SDK calls.

This project is ideal for learning:

LLM routing logic

Gemini function-calling patterns

Two-stage LLM architecture (planner â†’ executor)

Parsing, transforming, and analyzing financial data

Building a foundation that later integrates banking APIs

Debugging agent pipelines with global state

âœ¨ Key Features
ğŸ”¹ 1. Smart Question Routing (LLM #1)

The first model decides:

If the question can be answered using Plaid data, it triggers a function call

If not, it returns CANNOT_ANSWER_WITH_PLAID

Examples:

Question	Router Output
â€œHow much did I spend on groceries last month?â€	Calls get_plaid_transactions
â€œWhat is the S&P500?â€	CANNOT_ANSWER_WITH_PLAID
â€œShow my last 10 Starbucks charges.â€	Calls get_plaid_transactions
ğŸ”¹ 2. Fake Plaid API (Prototype Only)

Instead of calling real Plaid, this project provides a mock Plaid function that returns:

Dummy accounts

Dummy transactions

Realistic categories, merchants, dates, and amounts

This allows the LLM to run end-to-end without needing credentials or OAuth setup.

ğŸ”¹ 3. Analyst LLM (LLM #2)

After transactions are retrieved, a second LLM run:

Analyzes spending

Groups transactions by category

Computes totals

Answers the question naturally and clearly

Example output:

â€œYou spent $97.50 at restaurants between Oct 1â€“5, mostly at Uber Eats and Starbucks.â€

ğŸ”¹ 4. Global State Debugger

The system keeps a global dictionary storing:

Last user question

Router LLM raw output

Function call arguments

Mock Plaid results

Analysis prompt

Final LLM answer

This makes the pipeline fully transparent and easy to debug.

ğŸ§© Architecture
User Question
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM #1: Router Model   â”‚
â”‚  (Decides: Plaid or Not) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
   if Plaid relevant
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  get_plaid_transactions  â”‚   â† Fake Plaid API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM #2: Analyst Model  â”‚
â”‚ (Explain + Summarize)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      Final Answer

ğŸ›  Tech Stack

Python 3.10+

Google Gemini API (google-genai)

Function Calling

Mock Plaid API

CLI interface

ğŸ“ File Structure
project/
â”‚
â”œâ”€â”€ plaid_assistant.py     # Main script (router, tools, analyst, orchestrator)
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ requirements.txt       # Dependencies

â–¶ï¸ Usage

Install dependencies:

pip install google-genai python-dotenv


Set your Gemini API key:

export GEMINI_API_KEY="your_key_here"


Run the assistant:

python plaid_assistant.py


Example interaction:

You: How much did I spend on restaurants last month?
Assistant: You spent $97.50â€¦

ğŸ”® Future Enhancements

Replace fake Plaid API with real Plaid SDK calls

Add more tools:

get_accounts()

get_balances()

summarize_expenses()

detect_recurring_subscriptions()

Add a web UI (Streamlit or React)

Add multi-tool planning

Add budgets + alerts

Add multi-account support

ğŸ“˜ Summary

This project is a clean learning template for building agent-like LLM systems with tool calling, decomposition, and financial data analysis. It provides an extensible foundation for a full personal finance AI assistant.
